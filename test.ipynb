{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktsE8Ga0z6VW"
      },
      "source": [
        "# *Importing libraries*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LVtgV7OQz4mi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil \n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.io import imread, imsave\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import save_model, load_model, Model\n",
        "from tensorflow.keras.layers import Input, InputLayer, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\n",
        "from sklearn.metrics import classification_report\n",
        "#from keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import imutils\n",
        "from keras.models import Sequential\n",
        "import cv2 as cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg5AQ1wM0qXU"
      },
      "source": [
        "# *Working with data*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWWmMfX1CFG"
      },
      "source": [
        "Moving images from folders to bigger folder combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AEyluzQB1BwW"
      },
      "outputs": [],
      "source": [
        "classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "data_co = {}\n",
        "main_path = '/home/noor/Documents/new_test/data/'\n",
        "for path in os.listdir(main_path):\n",
        "  for img in os.listdir(f'{main_path}{path}'):\n",
        "    data_co[img] = path\n",
        "    shutil.move(f'{main_path}{path}/{img}', main_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHQ3jWTq1sRI"
      },
      "source": [
        "Removing folders "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "05pibRwA1q2L"
      },
      "outputs": [],
      "source": [
        "!rm -d '/home/noor/Documents/new_test/data/glioma'\n",
        "!rm -d '/home/noor/Documents/new_test/data/meningioma'\n",
        "!rm -d '/home/noor/Documents/new_test/data/notumor'\n",
        "!rm -d '/home/noor/Documents/new_test/data/pituitary'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLNoJmKU2CvX",
        "outputId": "ce812676-9ce9-4da4-8f2f-75c658c23088"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "notumor       2000\n",
              "pituitary     1757\n",
              "meningioma    1645\n",
              "glioma        1624\n",
              "Name: class, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = pd.DataFrame(data_co.items(), columns = ['image_id', 'class'])\n",
        "x['class'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEewz7Th2SVu"
      },
      "source": [
        "function to crop images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5fhuOWx_2RY0"
      },
      "outputs": [],
      "source": [
        "def crop_margins(path):\n",
        "  img = imread(path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  _,binary = cv2.threshold(gray, 20, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "  # find contours from thresholded image\n",
        "  contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  items = cv2.findContours(binary.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  contours = imutils.grab_contours(items)\n",
        "  c = max(contours, key =cv2.contourArea)\n",
        "  extLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
        "  extRight = tuple(c[c[:, :, 0].argmax()][0])\n",
        "  extTop = tuple(c[c[:, :, 1].argmin()][0])\n",
        "  extBot = tuple(c[c[:, :, 1].argmax()][0])\n",
        "  ADD_PIXELS = 0 \n",
        "  new_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS,extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
        "  \n",
        "  # image resizing\n",
        "  IMG_SIZE = 224\n",
        "  new_img = cv2.resize(new_img,(IMG_SIZE,IMG_SIZE))\n",
        "  return new_img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00ie2b-F4J7c"
      },
      "source": [
        "Applying cropping and resizing function on dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9ML8Zbb64NHv"
      },
      "outputs": [],
      "source": [
        "save_path = '/home/noor/Documents/new_test/dataset'\n",
        "in_path = os.path.join('/home/noor/Documents/new_test/data/')\n",
        "\n",
        "if not os.path.isdir(save_path):\n",
        "  os.makedirs(save_path)\n",
        "\n",
        "for img in os.listdir(in_path):\n",
        "  imsave(f'{save_path}/{img}', crop_margins(f'{in_path}/{img}'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5-lq13M5Ctw"
      },
      "source": [
        "Creating new sub folders "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4WThArip5EyP"
      },
      "outputs": [],
      "source": [
        "subfiles = ['/testing/glioma/' , '/testing/meningioma/' , '/testing/notumor/' ,\n",
        "'/testing/pituitary/','/training/glioma/' , '/training/meningioma/' , '/training/notumor/' , '/training/pituitary/', '/validation/glioma/',\n",
        "'/validation/meningioma/', '/validation/notumor/', '/validation/pituitary/']\n",
        "\n",
        "for path in subfiles:\n",
        "  if not os.path.isdir(f'{save_path}/{path}'):\n",
        "    os.makedirs(f'{save_path}/{path}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IIlWjwYe5YS_",
        "outputId": "af4a66f2-0497-4c2b-a709-8efde7b24954"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tr-me_0274.jpg</td>\n",
              "      <td>meningioma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tr-me_0858.jpg</td>\n",
              "      <td>meningioma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tr-me_1037.jpg</td>\n",
              "      <td>meningioma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tr-me_0821.jpg</td>\n",
              "      <td>meningioma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Tr-me_0308.jpg</td>\n",
              "      <td>meningioma</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         image_id       class\n",
              "0  Tr-me_0274.jpg  meningioma\n",
              "1  Tr-me_0858.jpg  meningioma\n",
              "2  Tr-me_1037.jpg  meningioma\n",
              "3  Tr-me_0821.jpg  meningioma\n",
              "4  Tr-me_0308.jpg  meningioma"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXnKLhRD5aiR"
      },
      "source": [
        "Splitting into training , validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CR0hwFbj5deD"
      },
      "outputs": [],
      "source": [
        "# training and testing set --> setting aside 20% of test , 80% of train \n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x[['image_id']].values, x[['class']].values, test_size = 0.2, random_state = 8)\n",
        "\n",
        "# using same function above to split the validation set (0.25*0.8=0.2)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.25, random_state=8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lJ0bitHvLHsg"
      },
      "outputs": [],
      "source": [
        "training = x_train.flatten().tolist()\n",
        "validation = x_val.flatten().tolist()\n",
        "testing = x_test.flatten().tolist()\n",
        "\n",
        "x.loc[x['image_id'].isin(training)].to_csv('training.csv', index=False, encoding='utf-8-sig')\n",
        "x.loc[x['image_id'].isin(validation)].to_csv('validation.csv', index=False, encoding='utf-8-sig')\n",
        "x.loc[x['image_id'].isin(testing)].to_csv('testing.csv', index=False, encoding='utf-8-sig')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XA8y4fxqLW1P"
      },
      "outputs": [],
      "source": [
        "testing = pd.read_csv('./testing.csv')\n",
        "validation = pd.read_csv('./validation.csv')\n",
        "training = pd.read_csv('./training.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-QhJfxVLapt"
      },
      "source": [
        "copying images into their subfolders "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "KnqmxhsOLeA1"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "main_path = '/home/noor/Documents/new_test/dataset'\n",
        "for indx, row in training.iterrows():\n",
        "    shutil.move(f\"{main_path}/{row['image_id']}\",f\"{main_path}/training/{row['class']}/{row['image_id']}\")\n",
        "\n",
        "for indx, row in validation.iterrows():\n",
        "    shutil.move(f\"{main_path}/{row['image_id']}\",f\"{main_path}/validation/{row['class']}/{row['image_id']}\")\n",
        "\n",
        "\n",
        "for indx,row in testing.iterrows():\n",
        "    shutil.move(f\"{main_path}/{row['image_id']}\",f\"{main_path}/testing/{row['class']}/{row['image_id']}\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj6aZ-y5oIaP",
        "outputId": "83c3cc9d-9fe5-49ad-cf8c-292055493017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4215, 1)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape # 60%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSdeOPUoK2f",
        "outputId": "d2a46705-19f6-4e09-9143-e52ffd8ac50b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1405, 1)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_val.shape # 20%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "De66y9n2oONn",
        "outputId": "fda43ca7-ddcc-405e-bdf9-e9d14a1d4ca5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1406, 1)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape # 20%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4SzovP5LoUl"
      },
      "source": [
        "# CNN Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2XPY-k5QLq8t"
      },
      "outputs": [],
      "source": [
        "# Model architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zzb7Aj-gLvFg"
      },
      "outputs": [],
      "source": [
        "image_shape = (224, 224, 3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9Hpt2Iwzgmx7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-08-06 17:36:24.692378: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/noor/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
            "2022-08-06 17:36:24.692417: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
            "2022-08-06 17:36:24.692439: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (noor): /proc/driver/nvidia/version does not exist\n",
            "2022-08-06 17:36:24.692827: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "# Model architecture NUMBER 1 \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3,3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(rate=0.2))\n",
        "\n",
        "model.add(Dense(4, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model architecture NUMBER 2\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(Conv2D(128,kernel_size=(3,3), activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPool2D(pool_size=(2,2)))\n",
        "model2.add(Dropout(rate=0.2))\n",
        "\n",
        "model2.add(Conv2D(64,kernel_size=(3,3), activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "model2.add(Conv2D(32,kernel_size=(3,3), activation='relu'))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dropout(rate=0.2))\n",
        "model2.add(Dense(512, activation='relu'))\n",
        "model2.add(Dropout(rate=0.2))\n",
        "\n",
        "model2.add(Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model architecture NUMBER 3\n",
        "\n",
        "model3 = Sequential()\n",
        "\n",
        "model3.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', input_shape=(224,224,3)))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model3.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "model3.add(Conv2D(32,kernel_size=(3,3), activation='relu'))\n",
        "model3.add(BatchNormalization())\n",
        "model3.add(MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(512, activation='relu'))\n",
        "model3.add(Dropout(rate=0.2))\n",
        "model3.add(Dense(512, activation='relu'))\n",
        "model3.add(Dropout(rate=0.2))\n",
        "\n",
        "model3.add(Dense(4, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZCi-kFGWjhkR"
      },
      "outputs": [],
      "source": [
        "train_data = ImageDataGenerator(rescale=1./255,\n",
        "                                    shear_range=0.2,\n",
        "                                    rotation_range=2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,\n",
        "                                    vertical_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kpvf3HjP1EJW",
        "outputId": "02b25e09-3682-4339-ac2e-7ca04e4045c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 4215 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_data.flow_from_directory(directory=\"/home/noor/Documents/new_test/dataset/training\",\n",
        "                                                  target_size=(224,224),\n",
        "                                                  class_mode='categorical',\n",
        "                                                  batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vYIMr0fK1VMI"
      },
      "outputs": [],
      "source": [
        "validation_data = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKf9HvEd1dyH",
        "outputId": "07456770-2cd1-418a-fde8-2499f4e24c08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1405 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "validation_set = validation_data.flow_from_directory(directory=\"/home/noor/Documents/new_test/dataset/validation\",\n",
        "                                                        target_size=(224,224),\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=1,\n",
        "                                                        shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1406 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_set = validation_data.flow_from_directory(directory=\"/home/noor/Documents/new_test/dataset/testing\",\n",
        "                                                        target_size=(224,224),\n",
        "                                                        class_mode='categorical',\n",
        "                                                        batch_size=1,\n",
        "                                                        shuffle = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xVnmCZh93h6o"
      },
      "outputs": [],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "fWMgwfqZ3K6b"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KSLmryza4x2p"
      },
      "outputs": [],
      "source": [
        "early = EarlyStopping(monitor = 'val_loss',\n",
        "                      min_delta = 0,\n",
        "                      patience = 8,\n",
        "                      verbose = 1,\n",
        "                      mode = 'auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "_3SpD_gi3cMj",
        "outputId": "b824af04-1410-48b4-f0f4-d2b85bb2dc41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 104s 787ms/step - loss: 0.1168 - accuracy: 0.9590 - val_loss: 0.3161 - val_accuracy: 0.9096\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 108s 819ms/step - loss: 0.1111 - accuracy: 0.9585 - val_loss: 0.3540 - val_accuracy: 0.8975\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 114s 860ms/step - loss: 0.1050 - accuracy: 0.9601 - val_loss: 0.1565 - val_accuracy: 0.9559\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 121s 915ms/step - loss: 0.1121 - accuracy: 0.9604 - val_loss: 1.0874 - val_accuracy: 0.7117\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 124s 936ms/step - loss: 0.0904 - accuracy: 0.9684 - val_loss: 0.1745 - val_accuracy: 0.9416\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 125s 949ms/step - loss: 0.1004 - accuracy: 0.9675 - val_loss: 0.1683 - val_accuracy: 0.9452\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 110s 835ms/step - loss: 0.1130 - accuracy: 0.9649 - val_loss: 0.2744 - val_accuracy: 0.9217\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 120s 912ms/step - loss: 0.1039 - accuracy: 0.9630 - val_loss: 0.3377 - val_accuracy: 0.8968\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 120s 907ms/step - loss: 0.0948 - accuracy: 0.9658 - val_loss: 0.1951 - val_accuracy: 0.9445\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 125s 944ms/step - loss: 0.0986 - accuracy: 0.9625 - val_loss: 0.3635 - val_accuracy: 0.8712\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 125s 942ms/step - loss: 0.1008 - accuracy: 0.9668 - val_loss: 1.3912 - val_accuracy: 0.7929\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ],
      "source": [
        "model_history = model.fit(x=training_set,validation_data=validation_set,epochs=50, callbacks = early,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1405/1405 [==============================] - 13s 9ms/step - loss: 1.3912 - accuracy: 0.7929\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.391221046447754, 0.7928825616836548]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(validation_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "132/132 [==============================] - 110s 828ms/step - loss: 1.1452 - accuracy: 0.5991 - val_loss: 1.3629 - val_accuracy: 0.4669\n",
            "Epoch 2/50\n",
            "132/132 [==============================] - 105s 793ms/step - loss: 0.6694 - accuracy: 0.7333 - val_loss: 1.2329 - val_accuracy: 0.5004\n",
            "Epoch 3/50\n",
            "132/132 [==============================] - 105s 794ms/step - loss: 0.5536 - accuracy: 0.7862 - val_loss: 0.6694 - val_accuracy: 0.7452\n",
            "Epoch 4/50\n",
            "132/132 [==============================] - 106s 800ms/step - loss: 0.4800 - accuracy: 0.8152 - val_loss: 0.6595 - val_accuracy: 0.7416\n",
            "Epoch 5/50\n",
            "132/132 [==============================] - 106s 803ms/step - loss: 0.4050 - accuracy: 0.8456 - val_loss: 0.7548 - val_accuracy: 0.7395\n",
            "Epoch 6/50\n",
            "132/132 [==============================] - 106s 798ms/step - loss: 0.3612 - accuracy: 0.8679 - val_loss: 0.7103 - val_accuracy: 0.7210\n",
            "Epoch 7/50\n",
            "132/132 [==============================] - 106s 804ms/step - loss: 0.3396 - accuracy: 0.8769 - val_loss: 0.6134 - val_accuracy: 0.7438\n",
            "Epoch 8/50\n",
            "132/132 [==============================] - 106s 800ms/step - loss: 0.2952 - accuracy: 0.8904 - val_loss: 0.4244 - val_accuracy: 0.8384\n",
            "Epoch 9/50\n",
            "132/132 [==============================] - 106s 803ms/step - loss: 0.2870 - accuracy: 0.8894 - val_loss: 0.7301 - val_accuracy: 0.7445\n",
            "Epoch 10/50\n",
            "132/132 [==============================] - 106s 803ms/step - loss: 0.2544 - accuracy: 0.9096 - val_loss: 1.1950 - val_accuracy: 0.6399\n",
            "Epoch 11/50\n",
            "132/132 [==============================] - 107s 808ms/step - loss: 0.2401 - accuracy: 0.9136 - val_loss: 1.1345 - val_accuracy: 0.6762\n",
            "Epoch 12/50\n",
            "132/132 [==============================] - 112s 848ms/step - loss: 0.2272 - accuracy: 0.9144 - val_loss: 1.0290 - val_accuracy: 0.7573\n",
            "Epoch 13/50\n",
            "132/132 [==============================] - 119s 897ms/step - loss: 0.2191 - accuracy: 0.9186 - val_loss: 1.6163 - val_accuracy: 0.7125\n",
            "Epoch 14/50\n",
            "132/132 [==============================] - 122s 922ms/step - loss: 0.2199 - accuracy: 0.9205 - val_loss: 0.3221 - val_accuracy: 0.8740\n",
            "Epoch 15/50\n",
            "132/132 [==============================] - 149s 1s/step - loss: 0.1783 - accuracy: 0.9326 - val_loss: 0.7274 - val_accuracy: 0.8050\n",
            "Epoch 16/50\n",
            "132/132 [==============================] - 171s 1s/step - loss: 0.1807 - accuracy: 0.9348 - val_loss: 0.8128 - val_accuracy: 0.7288\n",
            "Epoch 17/50\n",
            "132/132 [==============================] - 172s 1s/step - loss: 0.1652 - accuracy: 0.9388 - val_loss: 0.2276 - val_accuracy: 0.9260\n",
            "Epoch 18/50\n",
            "132/132 [==============================] - 177s 1s/step - loss: 0.1673 - accuracy: 0.9324 - val_loss: 0.6799 - val_accuracy: 0.7744\n",
            "Epoch 19/50\n",
            "132/132 [==============================] - 178s 1s/step - loss: 0.1616 - accuracy: 0.9423 - val_loss: 0.2364 - val_accuracy: 0.9139\n",
            "Epoch 20/50\n",
            "132/132 [==============================] - 179s 1s/step - loss: 0.1221 - accuracy: 0.9573 - val_loss: 0.3382 - val_accuracy: 0.8726\n",
            "Epoch 21/50\n",
            "132/132 [==============================] - 179s 1s/step - loss: 0.1311 - accuracy: 0.9533 - val_loss: 0.2606 - val_accuracy: 0.9082\n",
            "Epoch 22/50\n",
            "132/132 [==============================] - 162s 1s/step - loss: 0.1392 - accuracy: 0.9495 - val_loss: 0.9191 - val_accuracy: 0.7623\n",
            "Epoch 23/50\n",
            "132/132 [==============================] - 99s 752ms/step - loss: 0.1291 - accuracy: 0.9568 - val_loss: 0.4983 - val_accuracy: 0.8463\n",
            "Epoch 24/50\n",
            "132/132 [==============================] - 107s 810ms/step - loss: 0.1284 - accuracy: 0.9542 - val_loss: 0.2512 - val_accuracy: 0.9174\n",
            "Epoch 25/50\n",
            "132/132 [==============================] - 110s 830ms/step - loss: 0.1204 - accuracy: 0.9573 - val_loss: 0.2384 - val_accuracy: 0.9181\n",
            "Epoch 25: early stopping\n"
          ]
        }
      ],
      "source": [
        "model_history = model2.fit(x=training_set,validation_data=validation_set,epochs=50, callbacks = early,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "model3.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=opt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model3' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/home/noor/Documents/new_test/test.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/noor/Documents/new_test/test.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model_history \u001b[39m=\u001b[39m model3\u001b[39m.\u001b[39mfit(x\u001b[39m=\u001b[39mtraining_set,validation_data\u001b[39m=\u001b[39mvalidation_set,epochs\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m,batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m, callbacks \u001b[39m=\u001b[39m early,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model3' is not defined"
          ]
        }
      ],
      "source": [
        "model_history = model3.fit(x=training_set,validation_data=validation_set,epochs=50,batch_size=64, callbacks = early,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1406/1406 [==============================] - 12s 9ms/step - loss: 1.3735 - accuracy: 0.7873\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[1.3735157251358032, 0.787339985370636]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1406/1406 [==============================] - 12s 9ms/step - loss: 0.1946 - accuracy: 0.9403\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.194618821144104, 0.9402560591697693]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model2.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(true_lab,predict_lab,classes,path):\n",
        "  matrix_confusion = tf.math.confusion_matrix(labels=true_lab, predictions=predicted_lab, num_classes=len(classes))\n",
        "  ax = plt.subplot()\n",
        "  sns.heatmap(matrix_confusion, square=True, annot=True, cmap='Blues', fmt='d', cbar=True)\n",
        "  ax.set_xlabel('Predicted labels')\n",
        "  ax.set_ylabel('True labels')\n",
        "  ax.set_title('Confusion Matrix')\n",
        "  ax.xaxis.set_ticklabels(classes)\n",
        "  ax.yaxis.set_ticklabels(classes)\n",
        "  plt.savefig(f'{path}confusion_matrix.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dump_text(text,path):\n",
        "  text_file = open(path, \"w\")\n",
        "  text_file.write(text)\n",
        "  text_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "savepath = '/home/noor/Documents/new_test/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1406/1406 [==============================] - 12s 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      glioma       0.98      0.84      0.90       294\n",
            "  meningioma       0.86      0.94      0.90       358\n",
            "     notumor       0.96      0.99      0.97       397\n",
            "   pituitary       0.98      0.97      0.98       357\n",
            "\n",
            "    accuracy                           0.94      1406\n",
            "   macro avg       0.95      0.93      0.94      1406\n",
            "weighted avg       0.94      0.94      0.94      1406\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "p = model2.predict(test_set)\n",
        "predicted_lab = p.argmax(axis=-1)\n",
        "true_lab = test_set.classes\n",
        "plot_confusion_matrix(true_lab, predicted_lab, test_set.class_indices.keys(),savepath)\n",
        "report = classification_report(true_lab, predicted_lab, target_names=test_set.class_indices.keys())\n",
        "print(report)\n",
        "dump_text(report,f'{savepath}classification_report.txt')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
